{
    "arch": {
        "type": "ConvAutoEncoder_1st",
        "args": {}
    },
    "DataLoader": {
        "batch_size": 128,
        "shuffle": 0,
        "num_workers": 0,
        "drop_last" : 0
    },
    "optimizer": {
        "type": "Adam",
        "args":{
            "lr": 0.1,
            "weight_decay": 0
        }
    },
    "loss": "MSELoss",
    "lr_scheduler": {
        "type": "StepLR",
        "args": {
            "step_size": 10,
            "gamma": 0.1
        }
    },
    "trainer": {
        "epochs": 100,
        "save_dir": "/home/braden/Environments/Research/Audio/Research(Refactored)/Model/"
    },
    "paths": {
        "model" : "/media/braden/Rage Pro/lightning_logs/version_39/checkpoints/epoch=99-step=699.ckpt",
        "combined_audio" : "/media/braden/Rage Pro/MS-SNSD/NoisySpeech_testing/noisy4_SNRdb_0.0_clnsp4.wav",
        "clean_audio" : "/media/braden/Rage Pro/MS-SNSD/CleanSpeech_testing/clnsp4.wav",
        "denoised_audio" : "/media/braden/Rage Pro/Denoised/experiment19.wav"

    },
    "spectrograms" : 1,
    "file_name" : "experiment19.json",
    "NOTE" : "Trying to figure out how epxeriment 15 worked out so well. It may look as if l1 loss is working better even though MSE gets to a lower loss. About 3000 epochs of MSE gave us loss of .008 but poor results and 1000 epochs of l1 loss gave us "
}